{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer ,TFBertForSequenceClassification,pipeline\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No proper seating arrangement, very uncomforta...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The app for the event kept crashing. I wouldn'...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The live music performance was mesmerizing. Th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The event was absolutely fantastic! The atmosp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great networking opportunities and friendly st...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  No proper seating arrangement, very uncomforta...  negative\n",
       "1  The app for the event kept crashing. I wouldn'...  negative\n",
       "2  The live music performance was mesmerizing. Th...  positive\n",
       "3  The event was absolutely fantastic! The atmosp...  positive\n",
       "4  Great networking opportunities and friendly st...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('enhanced_event_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\",model=model,tokenizer =tokenizer,framework =\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for review in df['review']:\n",
    "    result = sentiment_pipeline(review)[0]\n",
    "    label = result['label']\n",
    "\n",
    "    # Map star ratings to your categories\n",
    "    if label in ['1 star', '2 stars']:\n",
    "        predictions.append('negative')\n",
    "    elif label == '3 stars':\n",
    "        predictions.append('neutral')\n",
    "    else:  # 4 or 5 stars\n",
    "        predictions.append('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_sentiment'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.8949\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85       333\n",
      "     neutral       0.87      0.81      0.84       333\n",
      "    positive       1.00      1.00      1.00       333\n",
      "\n",
      "    accuracy                           0.89       999\n",
      "   macro avg       0.90      0.89      0.89       999\n",
      "weighted avg       0.90      0.89      0.89       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(df['sentiment'], df['predicted_sentiment'])\n",
    "report = classification_report(df['sentiment'], df['predicted_sentiment'])\n",
    "\n",
    "print(f\"âœ… Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fine tuning the model\n",
    "def encode_reviews(reviews, tokenizer, max_len=128):\n",
    "    return tokenizer(list(reviews), padding='max_length', truncation=True, max_length=max_len, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encode_reviews(df['review'].tolist(), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {\n",
    "    'negative': 0,  # 1-2 stars\n",
    "    'neutral': 2,   # 3 stars\n",
    "    'positive': 4    # 4-5 stars\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment'].map(sentiment_map).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 4, 4, 4, 0, 4, 4, 4, 0, 0, 4, 2, 2, 4, 2, 0, 0, 0, 0, 0, 0,\n",
       "       0, 4, 0, 2, 2, 4, 4, 2, 2, 0, 4, 4, 2, 0, 2, 0, 4, 2, 4, 4, 2, 2,\n",
       "       2, 0, 4, 2, 0, 0, 4, 4, 0, 4, 0, 2, 4, 0, 4, 2, 2, 0, 2, 4, 0, 4,\n",
       "       4, 2, 2, 0, 4, 0, 0, 0, 2, 4, 2, 0, 0, 0, 4, 2, 4, 4, 0, 4, 0, 2,\n",
       "       0, 2, 0, 2, 2, 4, 2, 4, 2, 2, 0, 2, 2, 4, 2, 4, 0, 4, 2, 2, 4, 2,\n",
       "       0, 4, 0, 0, 0, 2, 0, 4, 4, 2, 0, 4, 2, 2, 0, 4, 4, 0, 2, 0, 4, 0,\n",
       "       2, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 0, 2, 4, 2, 2, 0, 4, 4, 0, 4, 2,\n",
       "       4, 0, 0, 0, 2, 0, 0, 4, 0, 4, 4, 0, 4, 2, 0, 4, 2, 2, 4, 4, 4, 4,\n",
       "       0, 2, 0, 0, 0, 2, 4, 0, 2, 4, 2, 2, 0, 2, 4, 0, 4, 0, 2, 2, 0, 4,\n",
       "       4, 4, 4, 4, 2, 0, 4, 4, 0, 4, 2, 2, 0, 4, 0, 4, 4, 2, 2, 4, 2, 2,\n",
       "       0, 2, 0, 2, 2, 4, 4, 0, 2, 0, 0, 0, 4, 0, 2, 2, 0, 0, 4, 4, 0, 4,\n",
       "       2, 4, 4, 0, 0, 4, 2, 0, 0, 2, 4, 0, 2, 4, 2, 0, 0, 2, 4, 0, 0, 0,\n",
       "       0, 2, 2, 2, 4, 4, 4, 2, 4, 4, 0, 0, 2, 0, 2, 0, 0, 2, 4, 2, 2, 2,\n",
       "       4, 4, 2, 4, 2, 4, 2, 0, 0, 4, 0, 0, 2, 2, 2, 2, 4, 2, 2, 0, 2, 0,\n",
       "       2, 4, 4, 4, 4, 2, 4, 0, 4, 0, 4, 2, 2, 4, 0, 0, 4, 2, 0, 0, 0, 4,\n",
       "       4, 0, 2, 0, 4, 4, 4, 4, 4, 2, 0, 4, 4, 2, 4, 0, 4, 2, 2, 2, 4, 4,\n",
       "       0, 0, 0, 4, 0, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 4, 0, 2, 2, 4, 2,\n",
       "       4, 0, 2, 0, 4, 4, 4, 0, 2, 2, 4, 4, 0, 0, 0, 2, 4, 4, 2, 2, 4, 2,\n",
       "       4, 2, 4, 0, 0, 0, 0, 4, 2, 0, 4, 4, 0, 2, 2, 2, 0, 2, 0, 2, 4, 0,\n",
       "       4, 4, 0, 2, 4, 2, 2, 4, 0, 0, 2, 4, 0, 0, 4, 2, 0, 0, 2, 4, 0, 0,\n",
       "       0, 2, 0, 0, 2, 2, 2, 2, 0, 4, 2, 0, 2, 2, 4, 0, 0, 2, 2, 0, 0, 2,\n",
       "       0, 4, 0, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 0, 0, 2, 2, 0, 2, 2, 0, 0,\n",
       "       4, 0, 4, 4, 4, 2, 0, 2, 2, 4, 4, 0, 4, 0, 0, 4, 4, 2, 4, 4, 4, 4,\n",
       "       0, 2, 0, 0, 2, 0, 0, 0, 4, 0, 0, 2, 0, 2, 2, 4, 4, 2, 2, 0, 2, 0,\n",
       "       2, 4, 2, 2, 2, 2, 0, 2, 4, 4, 4, 0, 0, 4, 0, 4, 4, 0, 0, 0, 2, 4,\n",
       "       0, 4, 0, 0, 2, 2, 4, 4, 4, 4, 4, 0, 0, 0, 4, 4, 2, 0, 0, 2, 4, 2,\n",
       "       0, 0, 2, 0, 4, 2, 2, 4, 4, 0, 4, 0, 2, 4, 2, 2, 0, 0, 0, 2, 4, 0,\n",
       "       4, 0, 0, 4, 2, 0, 2, 4, 0, 2, 2, 0, 2, 0, 0, 0, 4, 4, 0, 2, 2, 4,\n",
       "       0, 0, 4, 2, 2, 0, 0, 0, 0, 4, 2, 0, 2, 4, 0, 0, 4, 0, 2, 2, 4, 4,\n",
       "       4, 0, 4, 4, 0, 4, 2, 4, 2, 2, 4, 2, 2, 2, 0, 2, 0, 2, 2, 2, 4, 2,\n",
       "       4, 2, 2, 2, 4, 0, 4, 0, 4, 0, 2, 0, 0, 0, 2, 0, 0, 4, 4, 2, 0, 2,\n",
       "       4, 0, 0, 4, 2, 0, 0, 2, 4, 4, 4, 2, 2, 2, 0, 2, 0, 0, 0, 2, 4, 0,\n",
       "       4, 4, 4, 2, 4, 2, 0, 0, 0, 4, 0, 0, 0, 0, 2, 4, 2, 0, 2, 4, 4, 0,\n",
       "       4, 2, 2, 0, 4, 0, 0, 2, 2, 2, 2, 4, 4, 4, 0, 4, 4, 4, 2, 2, 4, 2,\n",
       "       2, 0, 0, 4, 2, 0, 2, 2, 4, 2, 2, 0, 0, 2, 0, 0, 2, 4, 4, 0, 2, 0,\n",
       "       4, 2, 2, 4, 4, 0, 2, 0, 4, 2, 0, 2, 2, 2, 4, 4, 0, 4, 0, 2, 4, 2,\n",
       "       4, 0, 4, 0, 0, 2, 4, 2, 2, 0, 2, 0, 2, 4, 0, 0, 4, 2, 4, 0, 4, 4,\n",
       "       0, 0, 4, 2, 2, 2, 0, 2, 4, 2, 2, 4, 4, 0, 2, 4, 2, 4, 2, 2, 2, 0,\n",
       "       0, 0, 0, 2, 2, 0, 4, 0, 4, 4, 2, 0, 2, 0, 2, 4, 0, 2, 4, 4, 2, 4,\n",
       "       0, 2, 2, 4, 0, 4, 0, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 2, 2,\n",
       "       2, 2, 0, 4, 2, 4, 0, 4, 4, 2, 4, 2, 4, 4, 0, 4, 0, 2, 4, 4, 2, 0,\n",
       "       0, 4, 2, 4, 4, 0, 2, 0, 4, 0, 0, 0, 4, 0, 4, 0, 0, 2, 4, 0, 2, 2,\n",
       "       0, 4, 4, 4, 4, 0, 2, 2, 2, 2, 4, 4, 2, 4, 2, 0, 2, 0, 0, 2, 4, 0,\n",
       "       0, 0, 2, 2, 0, 2, 2, 0, 4, 2, 4, 4, 2, 4, 2, 2, 0, 4, 0, 0, 4, 2,\n",
       "       4, 2, 0, 4, 2, 4, 2, 0, 0, 2, 0, 0, 4, 0, 0, 0, 4, 2, 4, 2, 0, 0,\n",
       "       0, 0, 4, 4, 2, 2, 0, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(X), y)).shuffle(len(y)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "63/63 [==============================] - 323s 5s/step - loss: 0.7217 - accuracy: 0.7347\n",
      "Epoch 2/2\n",
      "63/63 [==============================] - 293s 5s/step - loss: 0.0071 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x205534de810>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "EPOCHS = 2\n",
    "model.fit(train_dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification at 0x205535142c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# âœ… Inference on the test dataset\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for review, label in zip(df['review'], df['sentiment']):\n",
    "    inputs = tokenizer(review, return_tensors=\"tf\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    pred_label = tf.argmax(outputs.logits, axis=1).numpy()[0]\n",
    "    \n",
    "    predictions.append(pred_label)\n",
    "    true_labels.append(label)\n",
    "\n",
    "# âœ… Map predictions back to star labels\n",
    "label_map = {\n",
    "    0: 'negative',   # 1-2 stars\n",
    "    1: 'negative',   \n",
    "    2: 'neutral',     # 3 stars\n",
    "    3: 'positive',     # 4-5 stars\n",
    "    4: 'positive'\n",
    "}\n",
    "\n",
    "predicted_sentiment = [label_map[p] for p in predictions]\n",
    "\n",
    "# âœ… Calculate accuracy and classification report\n",
    "accuracy = accuracy_score(df['sentiment'], predicted_sentiment)\n",
    "report = classification_report(df['sentiment'], predicted_sentiment)\n",
    "\n",
    "print(f\"âœ… Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Attending this event was an absolute delight! The organizers did a phenomenal job ensuring everything was seamless, from the registration process to the closing ceremony. The speakers were incredibly insightful, offering fresh perspectives that kept the audience engaged. The ambiance was vibrant, and the catering was top-notch. I particularly loved the networking opportunities, as I met professionals who provided valuable insights into my field. Overall, a well-organized, highly enjoyable experience that I would definitely recommend!\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Review: The event had its ups and downs. While I appreciated the effort put into organizing it, I felt some aspects could have been improved. The keynote speakers were great, but the breakout sessions felt repetitive. The venue was decent, though the seating arrangements were a bit cramped. The networking session was useful, but I wish there were more structured ways to interact with other attendees. It wasnâ€™t the worst event Iâ€™ve been to, but it wasnâ€™t the best either.\n",
      "Predicted Sentiment: neutral\n",
      "\n",
      "Review: Honestly, I was quite disappointed with this event. The organization felt chaotic, and there were constant delays that threw off the schedule. The speakers, while knowledgeable, often went off-topic, making it hard to stay engaged. The venue was poorly chosen, with uncomfortable seating and bad acoustics that made it difficult to hear presentations clearly. The food options were extremely limited, and the networking opportunities were not well structured. I expected a lot more given the hype, but it felt like a waste of time and money.\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Review: This event was a disaster from start to finish. The check-in process was slow and disorganized, leading to long wait times. Several sessions were canceled last minute, and there was little communication from the organizers. The speakers were underwhelming, often reading straight from slides rather than engaging with the audience. The venue itself was overcrowded, making it difficult to move around. I left early out of frustration and will definitely not be attending again.\n",
      "Predicted Sentiment: negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# âœ… Map predictions back to star labels\n",
    "label_map = {\n",
    "    0: 'negative',   # 1-2 stars\n",
    "    1: 'negative',   \n",
    "    2: 'neutral',     # 3 stars\n",
    "    3: 'positive',     # 4-5 stars\n",
    "    4: 'positive'\n",
    "}\n",
    "new_reviews = [\n",
    "    \"Attending this event was an absolute delight! The organizers did a phenomenal job ensuring everything was seamless, from the registration process to the closing ceremony. The speakers were incredibly insightful, offering fresh perspectives that kept the audience engaged. The ambiance was vibrant, and the catering was top-notch. I particularly loved the networking opportunities, as I met professionals who provided valuable insights into my field. Overall, a well-organized, highly enjoyable experience that I would definitely recommend!\",\n",
    "\n",
    "    \"The event had its ups and downs. While I appreciated the effort put into organizing it, I felt some aspects could have been improved. The keynote speakers were great, but the breakout sessions felt repetitive. The venue was decent, though the seating arrangements were a bit cramped. The networking session was useful, but I wish there were more structured ways to interact with other attendees. It wasnâ€™t the worst event Iâ€™ve been to, but it wasnâ€™t the best either.\",\n",
    "\n",
    "    \"Honestly, I was quite disappointed with this event. The organization felt chaotic, and there were constant delays that threw off the schedule. The speakers, while knowledgeable, often went off-topic, making it hard to stay engaged. The venue was poorly chosen, with uncomfortable seating and bad acoustics that made it difficult to hear presentations clearly. The food options were extremely limited, and the networking opportunities were not well structured. I expected a lot more given the hype, but it felt like a waste of time and money.\",\n",
    "    \"This event was a disaster from start to finish. The check-in process was slow and disorganized, leading to long wait times. Several sessions were canceled last minute, and there was little communication from the organizers. The speakers were underwhelming, often reading straight from slides rather than engaging with the audience. The venue itself was overcrowded, making it difficult to move around. I left early out of frustration and will definitely not be attending again.\"\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "# âœ… Inference\n",
    "for review in new_reviews:\n",
    "    inputs = tokenizer(review, return_tensors=\"tf\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    pred_label = tf.argmax(outputs.logits, axis=1).numpy()[0]\n",
    "\n",
    "    sentiment = label_map[pred_label]\n",
    "    print(f\"Review: {review}\\nPredicted Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fine_tuned_nlptown_bert_model_ver2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fine_tuned_nlptown_bert_model_ver2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"fine_tuned_nlptown_bert_model_ver2\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Quantized model saved as TFLite.\n"
     ]
    }
   ],
   "source": [
    "##post training quantization\n",
    "import tensorflow as tf\n",
    "\n",
    "# âœ… Load the fine-tuned model\n",
    "model = tf.saved_model.load(\"fine_tuned_nlptown_bert_model\")\n",
    "\n",
    "# âœ… Convert the model to a TFLite model with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"fine_tuned_nlptown_bert_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# âœ… Save the quantized model\n",
    "with open(\"fine_tuned_nlptown_bert_model_quantized.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"ðŸ”¥ Quantized model saved as TFLite.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(\"fine_tuned_nlptown_bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Very Amazing experience i need refund for my ticket\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Review: It was an average experience , maybe I'll visit next time\n",
      "Predicted Sentiment: neutral\n",
      "\n",
      "Review: It was fun but food was very bad\n",
      "Predicted Sentiment: neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# âœ… Load Model\n",
    "model = tf.saved_model.load(\"fine_tuned_nlptown_bert_model\")\n",
    "infer = model.signatures[\"serving_default\"]\n",
    "\n",
    "# âœ… Label Map\n",
    "label_map = {\n",
    "    0: 'negative',   # 1-2 stars\n",
    "    1: 'negative',\n",
    "    2: 'neutral',     # 3 stars\n",
    "    3: 'positive',    # 4-5 stars\n",
    "    4: 'positive'\n",
    "}\n",
    "\n",
    "# âœ… Load Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# âœ… New Reviews\n",
    "new_reviews = [\n",
    "    \"Very Amazing experience i need refund for my ticket\",\n",
    "    \"It was an average experience , maybe I'll visit next time\",\n",
    "    \"It was fun but food was very bad\"\n",
    "]\n",
    "\n",
    "# âœ… Inference Loop\n",
    "for review in new_reviews:\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(review, return_tensors=\"tf\", padding=True, truncation=True)\n",
    "\n",
    "    # Prepare the inputs for the model\n",
    "    outputs = infer(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        token_type_ids=inputs.get('token_type_ids', tf.zeros_like(inputs['input_ids']))\n",
    "    )\n",
    "\n",
    "    # Extract logits and predict\n",
    "    logits = outputs['logits']\n",
    "    pred_label = tf.argmax(logits, axis=1).numpy()[0]\n",
    "\n",
    "    sentiment = label_map[pred_label]\n",
    "    print(f\"Review: {review}\\nPredicted Sentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "## tflite model is not working\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"fine_tuned_nlptown_bert_model_quantized.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We need to remove 14 to truncate the input but the first sequence has a length 13. \n",
      "We need to remove 10 to truncate the input but the first sequence has a length 9. \n",
      "We need to remove 12 to truncate the input but the first sequence has a length 11. \n",
      "We need to remove 10 to truncate the input but the first sequence has a length 9. \n",
      "We need to remove 11 to truncate the input but the first sequence has a length 10. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Review: It was an average experience, maybe I'll visit next time\n",
      "âœ… Predicted Sentiment: negative\n",
      "ðŸ“Š Confidence: 0.2560\n",
      "====================================================================================================\n",
      "ðŸ”¥ Review: It was fun but the food was very bad\n",
      "âœ… Predicted Sentiment: negative\n",
      "ðŸ“Š Confidence: 0.2560\n",
      "====================================================================================================\n",
      "ðŸ”¥ Review: Absolutely loved the movie! Great acting and storyline.\n",
      "âœ… Predicted Sentiment: negative\n",
      "ðŸ“Š Confidence: 0.2560\n",
      "====================================================================================================\n",
      "ðŸ”¥ Review: Worst customer service ever. Never coming back.\n",
      "âœ… Predicted Sentiment: negative\n",
      "ðŸ“Š Confidence: 0.2560\n",
      "====================================================================================================\n",
      "ðŸ”¥ Review: The concert was amazing, had a wonderful time!\n",
      "âœ… Predicted Sentiment: negative\n",
      "ðŸ“Š Confidence: 0.2560\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# âœ… Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# âœ… Label Map\n",
    "label_map = {\n",
    "    0: 'negative',   # 1-2 stars\n",
    "    1: 'negative',\n",
    "    2: 'neutral',     # 3 stars\n",
    "    3: 'positive',    # 4-5 stars\n",
    "    4: 'positive'\n",
    "}\n",
    "\n",
    "# âœ… Load Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# âœ… New Reviews\n",
    "new_reviews = [\n",
    "    \"It was an average experience, maybe I'll visit next time\",\n",
    "    \"It was fun but the food was very bad\",\n",
    "    \"Absolutely loved the movie! Great acting and storyline.\",\n",
    "    \"Worst customer service ever. Never coming back.\",\n",
    "    \"The concert was amazing, had a wonderful time!\"\n",
    "]\n",
    "\n",
    "# âœ… Check the expected input shape\n",
    "expected_shape = input_details[0]['shape']  # e.g., (1, 512)\n",
    "max_len = expected_shape[1]\n",
    "\n",
    "# âœ… Inference Loop\n",
    "for review in new_reviews:\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(review, return_tensors=\"tf\", padding='max_length', truncation=True, max_length=max_len)\n",
    "\n",
    "    # Prepare input tensors\n",
    "    input_ids = inputs['input_ids'].numpy().astype(np.int32)\n",
    "    attention_mask = inputs['attention_mask'].numpy().astype(np.int32)\n",
    "    token_type_ids = inputs.get('token_type_ids', tf.zeros_like(inputs['input_ids'])).numpy().astype(np.int32)\n",
    "\n",
    "    # Resize tensors to match TFLite input shape\n",
    "    input_ids = np.resize(input_ids, expected_shape)\n",
    "    attention_mask = np.resize(attention_mask, expected_shape)\n",
    "    token_type_ids = np.resize(token_type_ids, expected_shape)\n",
    "\n",
    "    # âœ… Set the input tensors\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_ids)\n",
    "    interpreter.set_tensor(input_details[1]['index'], attention_mask)\n",
    "    interpreter.set_tensor(input_details[2]['index'], token_type_ids)\n",
    "\n",
    "    # âœ… Run inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # âœ… Extract logits and apply softmax\n",
    "    logits = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    probabilities = softmax(logits)\n",
    "\n",
    "    # âœ… Get the predicted label\n",
    "    pred_label = np.argmax(probabilities)\n",
    "    confidence = probabilities[pred_label]\n",
    "\n",
    "    sentiment = label_map[pred_label]\n",
    "    \n",
    "    print(f\"ðŸ”¥ Review: {review}\")\n",
    "    print(f\"âœ… Predicted Sentiment: {sentiment}\")\n",
    "    print(f\"ðŸ“Š Confidence: {confidence:.4f}\")\n",
    "    print(\"=\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
